# CoinAfrique Animaux SÃ©nÃ©gal

Ce dÃ©pÃ´t contient une petite application **Streamlit** qui recense les annonces d'animaux publiÃ©es sur
CoinAfrique SÃ©nÃ©gal. Elle s'appuie sur un scraper dÃ©diÃ© et une base de donnÃ©es SQLite pour stocker
les rÃ©sultats.

---

## ğŸ“¦ Structure du projet

```
app.py              # Interface Streamlit (dark theme personnalisÃ©)
scraper.py          # Logique de rÃ©cupÃ©ration et de nettoyage des annonces
database.py         # Wrapper SQLite (3 tables : annonces brutes, nettoyÃ©es et Ã©valuations)

data/               # Copies CSV gÃ©nÃ©rÃ©es Ã  la main / sorties de scraping
web scraper/        # mÃªmes CSV (peut Ãªtre supprimÃ©)
utils/              # notebooks d'expÃ©rimentation
```

La base SQLite gÃ©nÃ©rÃ©e est `coinafrique.db` Ã  la racine.

## ğŸ”§ PrÃ©requis

- Python 3.8+ (le projet a Ã©tÃ© dÃ©veloppÃ© avec 3.13 sous Windows)
- La majoritÃ© des bibliothÃ¨ques se gÃ¨rent via `pip`.

Installer les dÃ©pendances :

```bash
pip install -r requirements.txt   # si vous ajoutez ce fichier
# ou simplement :
pip install streamlit pandas plotly beautifulsoup4 requests
```

> `sqlite3` fait partie de la bibliothÃ¨que standard de Python.

## ğŸš€ Lancer l'application

1. Positionnez-vous dans le dossier du projet :
   `cd c:\Users\chris\OneDrive\Desktop\coinafrique_animaux`
2. DÃ©marrez Streamlit :
   ```bash
   streamlit run app.py
   ```
3. L'interface s'ouvre dans le navigateur (http://localhost:8501 par dÃ©faut).

L'interface permet de visualiser des KPIs, des tableaux de donnÃ©es et de lancer un nouveau scraping.

## ğŸ›  Modules principaux

### `scraper.py`
- Contient des fonctions pour parcourir les catÃ©gories (`Chiens`, `Moutons`, ...)
- Garde en mÃ©moire des sÃ©lecteurs Â« fallback Â» robustes.
- Nettoie les donnÃ©es (prix, doublons, etc.) et retourne des `DataFrame`.
- Offre Ã©galement un utilitaire pour traiter un export de l'extension Web Scraper.

### `database.py`
- Initialise la base SQLite (3 tables).
- Fonctions de sauvegarde (`annonces_brutes`, `annonces_nettoyees`, `evaluations`).
- Quelques helpers de lecture/compte et de purge.

### `app.py`
- Interface Streamlit entiÃ¨rement stylisÃ©e en Â« dark premium Â».
- Utilise `scraper` et `database` pour rÃ©cupÃ©rer et afficher les annonces.
- PrÃ©voyez d'ajouter des Ã©valuations (table `evaluations`).

## ğŸ§ª DonnÃ©es existantes

Les sous-dossiers `data/` et `web scraper/` contiennent des exports `.csv` prÃ©cÃ©demment
utilisÃ©s pour tester. Ils ne sont pas nÃ©cessaires au fonctionnement de l'application mais
peuvent servir de base pour rÃ©-importer des annonces.

## ğŸ“ Suggestions

- Ajouter un `requirements.txt` ou `pyproject.toml` pour la gestion des dÃ©pendances.
- Mettre en place un fichier `.gitignore` pour exclure `__pycache__` et `coinafrique.db`.
- Documenter les workflows de scraping ou transformer `scraper` en package installable.

---

Â© 2026 â€” Utilisation libre, pas de licence explicite fournie.
